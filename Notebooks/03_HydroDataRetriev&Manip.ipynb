{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArlexMR/CEE_694_Python_Lecture/blob/main/Notebooks/03_HydroDataRetriev%26Manip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZYw5WyDfAWq"
      },
      "source": [
        "# Data Retrieval and Hydrological Applications\n",
        "\n",
        "This notebook shows a basic aplication of the retrieval and manipulation of daily discharge data using the `dataretrieval`  Python Package, and the libraries `Pandas` and `pymannkendall`.\n",
        "\n",
        "Unlike previous notebooks, this one is mainly demonstrative. You won't need to make major modifications to the code. However, feel free to play around with it and try your own analyses.  \n",
        "\n",
        "At the end, you will find some exercises to replicate this analysis with new data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzlvzaYXfAW4"
      },
      "source": [
        "# Install the Packages\n",
        "\n",
        "The following code installs the packages required. If running in a Jupyter notebook, this must be done only the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "UBODOLJ_fAW6"
      },
      "outputs": [],
      "source": [
        "!pip install dataretrieval\n",
        "!pip install pymannkendall"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ye3v51ht8734"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HdxLjmlufAXD"
      },
      "outputs": [],
      "source": [
        "from dataretrieval import nwis # For getting the data\n",
        "from IPython.display import display # Just a fancy 'plot()' for dataFrames\n",
        "\n",
        "import pandas as pd # For tabular data manipulation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # For creating charts\n",
        "import pymannkendall as mk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMzhXAiOfAXF"
      },
      "source": [
        "# What is dataretrieval?\n",
        "Dataretrieval is a Python alternative to USGS-R's dataRetrieval package for obtaining USGS or EPA water quality data, streamflow data, and metadata directly from web services. Note that dataretrieval is an alternative to the R package, not a port, in that it reproduces the functionality of the R package but its organization and functionality often differ. The Python version also expands upon its predecessor by including capability to pull data from a variety of web portals besides NWIS and STORET.  \n",
        "\n",
        "**Input Arguments:**\n",
        "\n",
        "* **sites** (string or list of strings): A list of USGS site identifiers for which to retrieve data.\n",
        "* **parameterCd** (list of strings): A list of USGS parameter codes for which to retrieve data. See: https://help.waterdata.usgs.gov/codes-and-parameters/parameters\n",
        "* **statCd** (list of strings): A list of USGS statistic codes for which to retrieve data. See: https://help.waterdata.usgs.gov/code/stat_cd_nm_query?stat_nm_cd=%25&fmt=html\n",
        "* **start** (string): The beginning date for a period for which to retrieve data. If the waterdata parameter startDT is supplied, it will overwrite the start parameter.\n",
        "* **end** (string): The ending date for a period for which to retrieve data. If the waterdata parameter endDT is supplied, it will overwrite the end parameter.  \n",
        "\n",
        "\n",
        "source: https://github.com/USGS-python/dataretrieval\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Some other retrieval functions are:**\n",
        "\n",
        "Function | Service\n",
        "---------|--------\n",
        "`get_iv` | Instantaneous (15 min) Values\n",
        "`get_dv` | Daily Values\n",
        "`get_stats` | Statistics\n",
        "`get_discharge_peaks` | Peak Flow\n",
        "`get_discharge_measurements` | Discharge Measurements\n",
        "`get_gwlevels`| Groundwater levels\n",
        "`get_qwdata` | Water quality"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Data"
      ],
      "metadata": {
        "id": "zQO1nEYwR2AY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1zGNZsaffAXL"
      },
      "outputs": [],
      "source": [
        "# Set the parameters needed to retrieve data\n",
        "siteNumber    = \"03298000\"\n",
        "parameterCode = \"00060\" # Discharge cfs\n",
        "startDate     = \"1900-01-01\"\n",
        "endDate       = \"2021-09-30\"\n",
        "\n",
        "# Retrieve the data\n",
        "(dailyStreamflow, info) = nwis.get_dv(sites    = siteNumber,\n",
        "                                   parameterCd = parameterCode,\n",
        "                                   start       = startDate,\n",
        "                                   end         = endDate\n",
        "                                   )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nwis.get_dv` returns a tuple whose first element is the data itself and the second element is the metadata. Both are Pandas `DataFrames`   "
      ],
      "metadata": {
        "id": "skFxHKKSR_y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the data"
      ],
      "metadata": {
        "id": "sJR5oShdxTtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tabular data and metadata"
      ],
      "metadata": {
        "id": "UiGmpolgxgN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data')\n",
        "display(dailyStreamflow.head())\n",
        "\n",
        "print('\\nMetadata: \\n')\n",
        "display(info.site_info()[0])"
      ],
      "metadata": {
        "id": "ht1c2t2TvpIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Look for missing values"
      ],
      "metadata": {
        "id": "ayuGggaTxdEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The  methods `info()` and `describe()` provides basic information of the Data Frame"
      ],
      "metadata": {
        "id": "iNs47xxZSydF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('BASIC INFO:')\n",
        "dailyStreamflow.info()\n",
        "\n",
        "print('\\nBASIC STATISTICS:')\n",
        "dailyStreamflow.describe()\n"
      ],
      "metadata": {
        "id": "S2IcBrjEzFLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot\n",
        "\n",
        "Here we use `matplotlib.pyplot` which was imported as `plt`.\n",
        "\n",
        "Here you can take a look at the variety of charts that can be created with `matplotlib`:  \n",
        "\n",
        "https://matplotlib.org/stable/gallery/index.html\n",
        "\n",
        "Another popular visualization library for Python is `seaborn` which is based on `matplotlib` and provides a high-level interface for beautiful charts:  \n",
        "\n",
        "https://seaborn.pydata.org/examples/index.html\n"
      ],
      "metadata": {
        "id": "eIXLhMLMzA2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here We will start with two basic `matplotlib` functions:\n",
        "\n",
        "`plt.figure()` creates the canvas for a new figure. Several parameters can be included. In this case, just the `figsize` is defined.  \n",
        "See: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html\n",
        "\n",
        "`plt.plot(x,y, ... )` plots $y$ vs. $x$ lines or markers. If only one array is provided it's used as $y$ and the $x$ is inferred\n",
        "see: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html  \n"
      ],
      "metadata": {
        "id": "3yHQgHXC4Qyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,3))\n",
        "plt.plot(dailyStreamflow['00060_Mean'])"
      ],
      "metadata": {
        "id": "jyLpiI79lM3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data flags\n",
        "Let's check the number and location of each flag in the time series"
      ],
      "metadata": {
        "id": "_tFjsLVaOyJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique values\n",
        "print(dailyStreamflow['00060_Mean_cd'].unique())\n",
        "# Print percentage of values for each flag\n",
        "dailyStreamflow.groupby('00060_Mean_cd').count()/len(dailyStreamflow)*100\n"
      ],
      "metadata": {
        "id": "uzLhbdEkO2QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot data with flags\n",
        "\n",
        "# split data according to flag\n",
        "flag_A = dailyStreamflow.loc[dailyStreamflow['00060_Mean_cd'] == 'A']\n",
        "flag_AR = dailyStreamflow.loc[dailyStreamflow['00060_Mean_cd'] == 'A, R']\n",
        "flag_Ae = dailyStreamflow.loc[dailyStreamflow['00060_Mean_cd'] == 'A, e']\n",
        "\n",
        "# plot each series with different color\n",
        "plt.figure(figsize = (15,3))\n",
        "plt.plot(flag_A['00060_Mean'],'.g', label = 'Flag: A')\n",
        "plt.plot(flag_AR['00060_Mean'],'.b', label = 'Flag: A, R')\n",
        "plt.plot(flag_Ae['00060_Mean'],'.r', label = 'Flag: A, e')\n",
        "plt.legend(loc = 'upper center', ncol = 3 )\n",
        "\n"
      ],
      "metadata": {
        "id": "lv5sXpozP2WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A list of (better) colors can be found here: https://matplotlib.org/stable/gallery/color/named_colors.html"
      ],
      "metadata": {
        "id": "JYMAJr2wZmz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Seasonality\n",
        "\n",
        "Seasonality refers to the typical variability along the year. Thus the mean discharge value for each of the twelve months must be estimated. Here, also the 5% and 95% quantiles are included. this is done with two simple steps:  \n",
        "1. Add a column with the month\n",
        "2. Use `groupby()` to estimate statistics for each of the unique values in the month column"
      ],
      "metadata": {
        "id": "SH8LbO6S2QIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dailyStreamflow.head()\n",
        "# Sometimes is convenient to have the date column as a normal column, besides having it in the index\n",
        "dailyStreamflow['Date'] = dailyStreamflow.index\n",
        "# In this case this date column is used to get the month for each data point\n",
        "dailyStreamflow['month'] = dailyStreamflow['Date'].dt.month\n",
        "\n",
        "# now let's estimate the mean, quantiles 5% and 95%, and number of samples for each month\n",
        "seasonalStreamFlow = pd.DataFrame()\n",
        "seasonalStreamFlow['mean_dschg'] = dailyStreamflow.groupby('month')['00060_Mean'].mean()\n",
        "seasonalStreamFlow['q5'] = dailyStreamflow.groupby('month')['00060_Mean'].quantile(0.05)\n",
        "seasonalStreamFlow['q95'] = dailyStreamflow.groupby('month')['00060_Mean'].quantile(0.95)\n",
        "seasonalStreamFlow['count'] = dailyStreamflow.groupby('month')['00060_Mean'].count()\n",
        "seasonalStreamFlow"
      ],
      "metadata": {
        "id": "ygaz16Q82SUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... and plot the results\n",
        "plt.figure(figsize = (8,3))\n",
        "\n",
        "# This creates the line with markers\n",
        "plt.plot(seasonalStreamFlow['mean_dschg'],\n",
        "         '-o',\n",
        "         c='k',\n",
        "         markerfacecolor = 'tab:red',\n",
        "         markersize = 8,\n",
        "         label = 'Mean daily discharge'\n",
        "         )\n",
        "\n",
        "# This creates a colored area\n",
        "plt.fill_between(seasonalStreamFlow.index,\n",
        "                 y1 = seasonalStreamFlow['q95'],\n",
        "                 y2 = seasonalStreamFlow['q5'],\n",
        "                 color = 'tab:grey',\n",
        "                 alpha = 0.3,\n",
        "                 label = '90% band'\n",
        "                 )\n",
        "plt.legend()\n",
        "\n",
        "plt.xticks(ticks=range(1,13),\n",
        "           labels = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'],\n",
        "           fontsize = 10\n",
        "           );\n",
        "plt.xlim(1,12)\n",
        "plt.yticks(fontsize = 10)\n",
        "plt.ylabel('Discharge (cfs)',fontsize = 13)\n"
      ],
      "metadata": {
        "id": "5Ynqoevd7pNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is there a trend?\n",
        "\n",
        "Let's look for trends in annual data. In this case we take 4 characteristics discharges for each year (min, max, mean, Quantile 95%) and plot them to look for temporal trend.\n",
        "\n",
        "The method `resample()` is useful for this task"
      ],
      "metadata": {
        "id": "GGv5lm2S9fZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dailyStreamflow.head()\n",
        "annual_Flow = pd.DataFrame()\n",
        "annual_Flow['min'] = dailyStreamflow['00060_Mean'].resample('1Y').min()\n",
        "annual_Flow['max'] = dailyStreamflow['00060_Mean'].resample('1Y').max()\n",
        "annual_Flow['mean'] = dailyStreamflow['00060_Mean'].resample('1Y').mean()\n",
        "annual_Flow['q95'] = dailyStreamflow['00060_Mean'].resample('1Y').quantile(0.95)\n",
        "annual_Flow['count'] = dailyStreamflow['00060_Mean'].resample('1Y').count()\n",
        "annual_Flow = annual_Flow[annual_Flow['count']/365>0.9] # remove years with less than 90% of the data\n",
        "annual_Flow\n",
        "\n"
      ],
      "metadata": {
        "id": "fTysJkRA9k3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple plot just to see what we got\n",
        "\n",
        "plt.figure(figsize = (10,6))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(annual_Flow['mean'],'.')\n",
        "plt.title('Mean')\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(annual_Flow['min'],'.')\n",
        "plt.title('Min')\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(annual_Flow['max'],'.')\n",
        "plt.title('Max')\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(annual_Flow['q95'],'.')\n",
        "plt.title('q95')\n",
        "\n",
        "plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "i6fT3nwq8lka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's include a *Moving Average* or *Rolling Mean*"
      ],
      "metadata": {
        "id": "mPnUCoYYXj6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rolling_annual_stats = annual_Flow.rolling(9, center = True ).agg({'min':'mean',\n",
        "                                            'max':'mean',\n",
        "                                            'mean':'mean',\n",
        "                                            'q95':'mean',\n",
        "                                            'count':'min'\n",
        "                                            })\n",
        "rolling_annual_stats.head(9)"
      ],
      "metadata": {
        "id": "LkiI21qOngTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ...and make a better plot\n",
        "plt.figure(figsize = (13,7), facecolor = 'w')\n",
        "\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(annual_Flow['max'],'or')\n",
        "plt.plot(rolling_annual_stats['max'],'k')\n",
        "plt.ylabel('Annual\\nMax. (cfs)', fontsize = 12)\n",
        "plt.xticks(color ='w')\n",
        "plt.yticks(fontsize = 10)\n",
        "\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(annual_Flow['mean'],'or')\n",
        "plt.plot(rolling_annual_stats['mean'],'k')\n",
        "plt.ylabel('Annual\\nMean (cfs)', fontsize = 12)\n",
        "plt.xticks(color ='w')\n",
        "plt.yticks(fontsize = 10)\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(annual_Flow['min'],'or')\n",
        "plt.plot(rolling_annual_stats['min'],'k')\n",
        "plt.ylabel('Annual\\nMin (cfs)', fontsize = 12)\n",
        "plt.xticks(color ='w')\n",
        "plt.yticks(fontsize = 10)\n",
        "\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(annual_Flow['q95'],'or')\n",
        "plt.plot(rolling_annual_stats['q95'],'k')\n",
        "plt.ylabel('Quantile\\n95% (cfs)', fontsize = 12)\n",
        "plt.yticks(fontsize = 10)\n",
        "plt.xticks(fontsize = 10)\n",
        "\n",
        "plt.suptitle('Discharge Trends Floyds Fork', fontsize = 15 )\n",
        "# plt.tight_layout(rect = (0,0,.95,0.95) )\n",
        "# plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "EOSwsMjwupNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's apply a Mann-Kendall test to the annual data"
      ],
      "metadata": {
        "id": "Jhv_UdGSfi5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mk_test = mk.original_test(annual_Flow['max'])\n",
        "print(mk_test)\n",
        "print(\"\\ntype of trend:\", mk_test.trend, \"(p-value: \", mk_test.p, \")\")"
      ],
      "metadata": {
        "id": "k1AB_yJvfzPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mk_test = mk.original_test(annual_Flow['q95'])\n",
        "print(mk_test)\n",
        "print(\"\\n type of trend:\", mk_test.trend, \"(p-value: \", mk_test.p, \")\")"
      ],
      "metadata": {
        "id": "EqF9bHBPgmiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flow duration curve\n",
        "\n",
        "Finally let's calculate and plot the flow duration curve which is frequently used in hydrological analyses.  \n",
        "\n",
        "Remember that the exceedence probability of given discharge can be estimated as:  \n",
        "\n",
        "$$P[Q>Q_0] = \\frac{m}{n+1}$$  \n",
        "\n",
        "where $m$ is the rank of $Q_0$ when the $Q$ series is sorted from the largest to the smallest value and $n$ is the number $Q$ values"
      ],
      "metadata": {
        "id": "r5SWtpwfAxBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Flow_dur = pd.DataFrame()\n",
        "# sort the data:\n",
        "Flow_dur['discharge'] = dailyStreamflow['00060_Mean'].sort_values(ascending = False)\n",
        "# Add a column with the rank\n",
        "Flow_dur['rank'] = range(1, len(Flow_dur)+1)\n",
        "# calculate exceedence probability\n",
        "Flow_dur['P_Exceed'] = 100* Flow_dur['rank']/(len(Flow_dur) + 1)\n",
        "\n",
        "# And plot\n",
        "plt.plot(Flow_dur['P_Exceed'], Flow_dur['discharge'],'k')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Exceedence probability')\n",
        "plt.ylabel('Discharge')\n"
      ],
      "metadata": {
        "id": "CKbsw_JOAz9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export data\n",
        "\n",
        "Each of the Data Frames generated can be exported to `csv` format using the method: `to_csv()`:"
      ],
      "metadata": {
        "id": "-TCtAXHBZj1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Flow_dur.to_csv('Flow_duration_curve.csv')"
      ],
      "metadata": {
        "id": "NmqvXtRvZlM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data\n",
        "A `csv` file can also be imported with the pandas function: `pd.read_csv()`:\n"
      ],
      "metadata": {
        "id": "6i5qScylfv18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_csv = pd.read_csv('Flow_duration_curve.csv')\n",
        "my_csv"
      ],
      "metadata": {
        "id": "9K03xXfdfxkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "Prior to starting any of these notebooks, please make sure to save a copy of this to your google drive. This can be done by navigating to *file* > *Save a copy in Drive*. Your changes will not be saved unless this has been completed.\n",
        "\n",
        "**NOTE: It is okay to work in groups to complete this assignment - but the assignment must be turned in and completed individually**"
      ],
      "metadata": {
        "id": "Mn5xQykZyNM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1 - 2 points\n",
        "\n",
        "1. Rerun this notebook to calculate flow trends at USGS gage 03293000. However, instead of plotting the q95, please plot the q50. Hint, under the section \"Is there a trend?\" Change `annual_Flow['q95'] = dailyStreamflow['00060_Mean'].resample('1Y').quantile(0.95)` to `annual_Flow['q50'] = dailyStreamflow['00060_Mean'].resample('1Y').quantile(0.50)`. Note, since you are changing `q95` to `q50`, all code below this referencing `q95` must also be changed to `q50`!\n",
        "2. Please retitle the plot, \"Discharge Trends\" to \"Discharge Trends 03293000 - MF Beargrass Creek at Old Cannons.\"\n",
        "3. Please right click the plot, choose *save image as* and save the figure somewhere on your desktop. We will later bring the plot into Microsoft Word."
      ],
      "metadata": {
        "id": "rRyXekGDyVjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2 - 3 points\n",
        "Each of you have been assigned a USGS gage in Louisville, as shown in the table below.\n",
        "\n",
        "Gage Number | Description | Student   \n",
        "---------|-------|-------\n",
        "03302000 | Pond Creek Near Louisville | Ellie, Lauren, Nick, Valerie  \n",
        "03298000 | FLoyds Fork at Fisherville | Karina, McKenna, Noah\n",
        "\n",
        "1. Under the section, \"Get Data,\" please include a line of code that changes gage 03293000 to your assigned gage.\n",
        "2. Please rerun the notebook to see flow trends at your assigned site (including qmin, qmax, qmean, and q50).\n",
        "3. Please retitle the plot, \"Discharge Trends\" to \"Discharge Trends [insert the number and name of your gage].\"\n",
        "4. Please right click the plot, choose *save image as* and save the figure somewhere on your desktop. We will later bring the plot into Microsoft Word.\n",
        "\n"
      ],
      "metadata": {
        "id": "7xqmrFp41Jdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3 - 10 points\n",
        "Please answer the following questions related to flow trends in Jefferson County in a separate Microsoft Word document.\n",
        "1. Please show the figures plotting flow trends for USGS gage 03293000 (Middle Fork of Beargrass Creek at Old Cannons) and your assigned USGS gage.\n",
        "2. How do flow trends differ between USGS gage 03293000 (Middle Fork of Beargrass Creek at Old Cannons) and your assigned USGS gage? In a concise paragraph, please hypothesize some potential reasons for differences in the trends. Note it may be helpful to gather information (e.g., watershed area, land use/land cover) on the watershed upstream of your gage from StreamStats.\n",
        "3. What are potential mechanisms driving the trends that you may have observed both upstream of gage 03293000 and upstream of your assigned gage? Please explain your reasoning.\n",
        "4. Noting that only three gages in Louisville have data dating back to the 1940s, to what degree could increased data collection improve understanding of long-term hydrologic trends?  \n",
        "5. Please write a brief (i.e., ~ 3 sentence) reflection on how tools like Google Collab and Python can be used to conduct research/engineering work.  "
      ],
      "metadata": {
        "id": "MSSteH_73hJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 4\n",
        "Please upload your Microsoft Word document as a PDF to Blackboard under the submission for Homework 3 part 3."
      ],
      "metadata": {
        "id": "46pkD7QN52Mr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}